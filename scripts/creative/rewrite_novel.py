#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°è¯´æ”¹å†™è„šæœ¬ï¼ˆå¢å¼ºç‰ˆï¼‰
åŠŸèƒ½ï¼š
- é˜…è¯»å¹¶ç†è§£å°è¯´å†…å®¹
- æç‚¼æ•…äº‹è„‰ç»œã€äººç‰©å½¢è±¡ã€æƒ…èŠ‚èµ·ä¼
- æ”¹å†™å°è¯´é£æ ¼
- è½¬æ¢äººç§°è§†è§’
- æ›¿æ¢äººç‰©å§“å
- å¤šç§é£æ ¼é€‰é¡¹
"""

import os
import re
import sys
import json
import random
from typing import Dict, List, Optional, Set, Tuple
from collections import Counter, defaultdict

# å¯¼å…¥AIå’Œåˆ›æ„å¤„ç†æ¨¡å—
import sys
import os

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
parent_dir = os.path.dirname(os.path.dirname(__file__))
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)

try:
    from scripts.ai.integration import UnifiedRewriter, CreativeAIEngine, create_engine
    from scripts.ai.analyzers.ai_analyzer import AIAnalyzerFactory
    AI_AVAILABLE = True
    INTEGRATION_AVAILABLE = True
except ImportError:
    try:
        # å°è¯•ç›¸å¯¹å¯¼å…¥
        from ..ai.integration import UnifiedRewriter, CreativeAIEngine, create_engine
        from ..ai.analyzers.ai_analyzer import AIAnalyzerFactory
        AI_AVAILABLE = True
        INTEGRATION_AVAILABLE = True
    except ImportError:
        try:
            # é™çº§åˆ°ç›´æ¥å¯¼å…¥
            sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'ai', 'analyzers'))
            sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'ai', 'models'))
            from ai_analyzer import AIAnalyzerFactory
            AI_AVAILABLE = True
            INTEGRATION_AVAILABLE = False
        except ImportError:
            AI_AVAILABLE = False
            INTEGRATION_AVAILABLE = False
            print("âš ï¸  AIåˆ†æå™¨æ¨¡å—æœªæ‰¾åˆ°ï¼Œå°†ä½¿ç”¨ä¼ ç»Ÿåˆ†ææ–¹æ³•")

# å°è¯•å¯¼å…¥æ™ºèƒ½æ–‡æœ¬å¤„ç†å™¨
try:
    from scripts.creative.processors.text_processor import NaturalStyleRewriter
    NATURAL_REWRITER_AVAILABLE = True
except ImportError:
    try:
        from .processors.text_processor import NaturalStyleRewriter
        NATURAL_REWRITER_AVAILABLE = True
    except ImportError:
        try:
            sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'processors'))
            from text_processor import NaturalStyleRewriter
            NATURAL_REWRITER_AVAILABLE = True
        except ImportError:
            NATURAL_REWRITER_AVAILABLE = False


class NovelAnalyzer:
    """å°è¯´åˆ†æå™¨"""
    
    def __init__(self, content: str):
        self.content = content
        self.characters = {}  # äººç‰©ä¿¡æ¯
        self.storyline = []   # æ•…äº‹è„‰ç»œ
        self.plot_points = [] # æƒ…èŠ‚è½¬æŠ˜ç‚¹
        self.chapters = []    # ç« èŠ‚ä¿¡æ¯
    
    def extract_characters(self) -> Dict[str, Dict]:
        """
        æå–äººç‰©ä¿¡æ¯
        
        Returns:
            äººç‰©å­—å…¸ï¼ŒåŒ…å«å§“åã€å‡ºç°æ¬¡æ•°ã€è§’è‰²ç±»å‹ç­‰
        """
        # æ’é™¤è¯åˆ—è¡¨ï¼ˆä¸æ˜¯äººåçš„å¸¸è§è¯ï¼‰
        exclude_words = {
            'å¤§å®¶', 'è‡ªå·±', 'ä»–ä»¬', 'æˆ‘ä»¬', 'ä½ ä»¬', 'å¥¹ä»¬', 'å®ƒä»¬',
            'ä»€ä¹ˆ', 'æ€ä¹ˆ', 'è¿™æ ·', 'é‚£æ ·', 'è¿™ä¸ª', 'é‚£ä¸ª', 'è¿™äº›', 'é‚£äº›',
            'ä»Šå¤©', 'æ˜å¤©', 'æ˜¨å¤©', 'ç°åœ¨', 'ä»¥å', 'ä¹‹å‰', 'ä¹‹å',
            'å¼€å§‹', 'ç»“æŸ', 'å®Œæˆ', 'ç»§ç»­', 'ç„¶å', 'æ¥ç€', 'æœ€å',
            'ç¬¬ä¸€', 'ç¬¬äºŒ', 'ç¬¬ä¸‰', 'ç¬¬å››', 'ç¬¬äº”', 'ç¬¬å…­', 'ç¬¬ä¸ƒ', 'ç¬¬å…«', 'ç¬¬ä¹', 'ç¬¬å',
            'ä¸€ä¸ª', 'ä¸¤ä¸ª', 'ä¸‰ä¸ª', 'å››ä¸ª', 'äº”ä¸ª',
            'è¿™é‡Œ', 'é‚£é‡Œ', 'å“ªé‡Œ', 'è¿™è¾¹', 'é‚£è¾¹',
            'ç»“å©š', 'æ‹’ç»', 'ä¸´æ—¶', 'å½©ç¤¼', 'ä¹‹å', 'å½“å¤©',
            'ç‚¹å¤´', 'ç¬‘é“', 'è¯´é“', 'è¯´é“', 'è¯´é“', 'è¯´é“',
            'å“ˆå“ˆ', 'å‘µå‘µ', 'å˜¿å˜¿', 'å˜»å˜»',
            'å°è¯´', 'ç« èŠ‚', 'å†…å®¹', 'æ ‡é¢˜', 'ä½œè€…', 'ç®€ä»‹',
        }
        
        # æ›´ç²¾ç¡®çš„å§“åæ¨¡å¼ï¼šå¸¸è§ä¸­æ–‡å§“æ° + åå­—ï¼ˆ2-3ä¸ªå­—ï¼‰
        common_surnames = ['ç‹', 'æ', 'å¼ ', 'åˆ˜', 'é™ˆ', 'æ¨', 'èµµ', 'é»„', 'å‘¨', 'å´',
                          'å¾', 'å­™', 'èƒ¡', 'æœ±', 'é«˜', 'æ—', 'ä½•', 'éƒ­', 'é©¬', 'ç½—',
                          'æ¢', 'å®‹', 'éƒ‘', 'è°¢', 'éŸ©', 'å”', 'å†¯', 'äº', 'è‘£', 'è§',
                          'ç¨‹', 'æ›¹', 'è¢', 'é‚“', 'è®¸', 'å‚…', 'æ²ˆ', 'æ›¾', 'å½­', 'å•',
                          'è‹', 'å¢', 'è’‹', 'è”¡', 'è´¾', 'ä¸', 'é­', 'è–›', 'å¶', 'é˜']
        
        # æ–¹æ³•1: æŸ¥æ‰¾"å§“æ°+åå­—"æ¨¡å¼
        surname_pattern = '|'.join(common_surnames)
        name_pattern1 = rf'({surname_pattern})[ä¸€-é¾¥]{{1,2}}(?=[ï¼Œã€‚ï¼ï¼Ÿï¼šï¼›\s]|$)'
        
        # æ–¹æ³•2: æŸ¥æ‰¾å¼•å·å†…çš„ç§°å‘¼ï¼ˆå¯èƒ½æ˜¯äººåï¼‰
        quote_pattern = r'["""]([ä¸€-é¾¥]{2,3})["""]'
        
        # æ–¹æ³•3: æŸ¥æ‰¾"XXè¯´"ã€"XXé“"ç­‰æ¨¡å¼
        speech_pattern = r'([ä¸€-é¾¥]{2,3})(?:è¯´|é“|é—®|ç­”|å–Š|å«|æƒ³|çœ‹|å¬|èµ°|æ¥|å»)(?=[ï¼Œã€‚ï¼ï¼Ÿï¼šï¼›\s]|$)'
        
        potential_names = set()
        
        # æå–æ‰€æœ‰å¯èƒ½çš„å§“å
        for pattern in [name_pattern1, quote_pattern, speech_pattern]:
            matches = re.findall(pattern, self.content)
            potential_names.update(matches)
        
        # è¿‡æ»¤æ’é™¤è¯
        potential_names = {name for name in potential_names 
                         if name not in exclude_words 
                         and len(name) >= 2 
                         and len(name) <= 4}
        
        # ç»Ÿè®¡å‡ºç°é¢‘ç‡
        name_counter = Counter()
        for name in potential_names:
            # ä½¿ç”¨å•è¯è¾¹ç•ŒåŒ¹é…ï¼Œé¿å…éƒ¨åˆ†åŒ¹é…
            pattern = r'(?<![ä¸€-é¾¥])' + re.escape(name) + r'(?![ä¸€-é¾¥])'
            count = len(re.findall(pattern, self.content))
            if count >= 10:  # æé«˜é˜ˆå€¼ï¼Œå‡å°‘è¯¯è¯†åˆ«
                name_counter[name] = count
        
        # è¿›ä¸€æ­¥è¿‡æ»¤ï¼šæ£€æŸ¥æ˜¯å¦å‡ºç°åœ¨å¯¹è¯æˆ–åŠ¨ä½œä¸­
        characters = {}
        for name, count in name_counter.most_common(30):
            # æ£€æŸ¥æ˜¯å¦å‡ºç°åœ¨åˆç†çš„ä¸Šä¸‹æ–‡ä¸­
            pattern = r'(?<![ä¸€-é¾¥])' + re.escape(name) + r'(?![ä¸€-é¾¥])'
            matches = list(re.finditer(pattern, self.content))[:5]
            
            valid = False
            for match in matches:
                start = max(0, match.start() - 20)
                end = min(len(self.content), match.end() + 20)
                context = self.content[start:end]
                # æ£€æŸ¥æ˜¯å¦åœ¨å¯¹è¯ã€åŠ¨ä½œç­‰åˆç†ä¸Šä¸‹æ–‡ä¸­
                if any(keyword in context for keyword in ['è¯´', 'é“', 'é—®', 'ç­”', 'æƒ³', 'çœ‹', 'èµ°', 'æ¥', 'å»', 'çš„', 'æ˜¯']):
                    valid = True
                    break
            
            if valid:
                role_type = self._classify_character(name, count)
                characters[name] = {
                    'name': name,
                    'count': count,
                    'role': role_type,
                    'mentions': []
                }
        
        # æå–äººç‰©å‡ºç°çš„ä¸Šä¸‹æ–‡
        for name in characters.keys():
            mentions = []
            pattern = r'(?<![ä¸€-é¾¥])' + re.escape(name) + r'(?![ä¸€-é¾¥])'
            for match in re.finditer(pattern, self.content):
                start = max(0, match.start() - 50)
                end = min(len(self.content), match.end() + 50)
                context = self.content[start:end]
                mentions.append(context)
            characters[name]['mentions'] = mentions[:10]
        
        self.characters = characters
        print(f"ğŸ“Š è¯†åˆ«åˆ° {len(characters)} ä¸ªä¸»è¦äººç‰©")
        if characters:
            top_chars = sorted(characters.items(), key=lambda x: x[1]['count'], reverse=True)[:5]
            print(f"   ä¸»è¦äººç‰©: {', '.join([name for name, _ in top_chars])}")
        return characters
    
    def _classify_character(self, name: str, count: int) -> str:
        """åˆ†ç±»è§’è‰²ç±»å‹"""
        # æ ¹æ®å‡ºç°é¢‘ç‡åˆ¤æ–­
        if count > 100:
            return 'ä¸»è§’'
        elif count > 50:
            return 'ä¸»è¦è§’è‰²'
        elif count > 20:
            return 'é…è§’'
        else:
            return 'æ¬¡è¦è§’è‰²'
    
    def analyze_storyline(self) -> List[Dict]:
        """
        åˆ†ææ•…äº‹è„‰ç»œ
        
        Returns:
            æ•…äº‹è„‰ç»œåˆ—è¡¨
        """
        # åˆ†å‰²ç« èŠ‚
        chapter_pattern = r'ç¬¬\s*(\d+)\s*ç« [ï¼š:ï¼š]?\s*(.*?)\n'
        chapters = []
        
        for match in re.finditer(chapter_pattern, self.content):
            chapter_num = int(match.group(1))
            chapter_title = match.group(2).strip() if match.group(2) else f"ç¬¬{chapter_num}ç« "
            start_pos = match.end()
            
            # æŸ¥æ‰¾ä¸‹ä¸€ç« ä½ç½®
            next_match = None
            for next_match_iter in re.finditer(chapter_pattern, self.content):
                if next_match_iter.start() > match.start():
                    next_match = next_match_iter
                    break
            
            end_pos = next_match.start() if next_match else len(self.content)
            chapter_content = self.content[start_pos:end_pos]
            
            chapters.append({
                'num': chapter_num,
                'title': chapter_title,
                'content': chapter_content,
                'length': len(chapter_content),
                'key_events': self._extract_key_events(chapter_content)
            })
        
        self.chapters = chapters
        self.storyline = chapters
        
        print(f"ğŸ“– åˆ†æå®Œæˆï¼Œå…± {len(chapters)} ä¸ªç« èŠ‚")
        return chapters
    
    def _extract_key_events(self, content: str) -> List[str]:
        """æå–å…³é”®äº‹ä»¶"""
        events = []
        
        # æŸ¥æ‰¾å…³é”®åŠ¨ä½œè¯
        action_patterns = [
            r'[^ã€‚ï¼ï¼Ÿ]{0,30}(å‘ç°|é‡åˆ°|å†³å®š|å¼€å§‹|ç»“æŸ|ç¦»å¼€|åˆ°è¾¾|æ‰¾åˆ°|å¤±å»)[^ã€‚ï¼ï¼Ÿ]{0,30}[ã€‚ï¼ï¼Ÿ]',
            r'[^ã€‚ï¼ï¼Ÿ]{0,30}(çªç„¶|å¿½ç„¶|ç»ˆäº|ç«Ÿç„¶|æ²¡æƒ³åˆ°)[^ã€‚ï¼ï¼Ÿ]{0,30}[ã€‚ï¼ï¼Ÿ]',
        ]
        
        for pattern in action_patterns:
            matches = re.findall(pattern, content)
            events.extend(matches[:3])  # æ¯ç« æœ€å¤š3ä¸ªå…³é”®äº‹ä»¶
        
        return events
    
    def analyze_plot_structure(self) -> Dict:
        """
        åˆ†ææƒ…èŠ‚ç»“æ„
        
        Returns:
            æƒ…èŠ‚ç»“æ„ä¿¡æ¯
        """
        plot_structure = {
            'beginning': [],  # å¼€ç«¯
            'development': [], # å‘å±•
            'climax': [],     # é«˜æ½®
            'ending': []      # ç»“å°¾
        }
        
        if not self.chapters:
            self.analyze_storyline()
        
        total_chapters = len(self.chapters)
        
        # æ ¹æ®ç« èŠ‚ä½ç½®åˆ’åˆ†æƒ…èŠ‚é˜¶æ®µ
        for i, chapter in enumerate(self.chapters):
            position = i / total_chapters if total_chapters > 0 else 0
            
            if position < 0.2:
                plot_structure['beginning'].append(chapter)
            elif position < 0.7:
                plot_structure['development'].append(chapter)
            elif position < 0.9:
                plot_structure['climax'].append(chapter)
            else:
                plot_structure['ending'].append(chapter)
        
        self.plot_points = plot_structure
        return plot_structure
    
    def generate_summary(self) -> Dict:
        """ç”Ÿæˆæ•…äº‹æ‘˜è¦"""
        summary = {
            'total_chapters': len(self.chapters),
            'total_characters': len(self.characters),
            'main_characters': [],
            'story_arc': '',
            'key_themes': []
        }
        
        # ä¸»è¦äººç‰©ï¼ˆæŒ‰å‡ºç°é¢‘ç‡ï¼‰
        if self.characters:
            main_chars = sorted(self.characters.items(), 
                              key=lambda x: x[1]['count'], reverse=True)[:5]
            summary['main_characters'] = [name for name, _ in main_chars]
        
        # æ•…äº‹å¼§çº¿
        if self.plot_points:
            summary['story_arc'] = f"å¼€ç«¯({len(self.plot_points['beginning'])}ç« ) -> " \
                                 f"å‘å±•({len(self.plot_points['development'])}ç« ) -> " \
                                 f"é«˜æ½®({len(self.plot_points['climax'])}ç« ) -> " \
                                 f"ç»“å°¾({len(self.plot_points['ending'])}ç« )"
        
        return summary


class CharacterNameMapper:
    """äººç‰©å§“åæ˜ å°„å™¨"""
    
    def __init__(self):
        self.name_mapping = {}
        self.name_pool = {
            'male': ['å¼ ä¼Ÿ', 'ç‹å¼º', 'ææ˜', 'åˆ˜æ´‹', 'é™ˆå†›', 'æ¨ç£Š', 'èµµåˆš', 'é»„å‹‡', 
                    'å‘¨æ°', 'å´æ–Œ', 'å¾æ¶›', 'å­™æµ©', 'é©¬è¶…', 'æœ±å³°', 'èƒ¡äº®'],
            'female': ['æå¨œ', 'ç‹èŠ³', 'å¼ æ•', 'åˆ˜é™', 'é™ˆä¸½', 'æ¨é›ª', 'èµµç³', 'é»„æ¢…',
                      'å‘¨é›¨', 'å´å©·', 'å¾é›¯', 'å­™æ‚¦', 'é©¬è‰', 'æœ±æ¬£', 'èƒ¡é¢–'],
            'surname': ['å¼ ', 'ç‹', 'æ', 'åˆ˜', 'é™ˆ', 'æ¨', 'èµµ', 'é»„', 'å‘¨', 'å´', 
                       'å¾', 'å­™', 'é©¬', 'æœ±', 'èƒ¡', 'æ—', 'ä½•', 'é«˜', 'æ¢', 'éƒ‘']
        }
        self.used_names = set()
    
    def generate_name(self, gender: str = 'unknown') -> str:
        """ç”Ÿæˆæ–°å§“å"""
        if gender == 'male' or gender == 'unknown':
            pool = self.name_pool['male'] + self.name_pool['female']
        else:
            pool = self.name_pool['female']
        
        # æ‰¾åˆ°æœªä½¿ç”¨çš„å§“å
        available = [n for n in pool if n not in self.used_names]
        if not available:
            # å¦‚æœéƒ½ç”¨å®Œäº†ï¼Œç»„åˆç”Ÿæˆ
            surname = self.name_pool['surname'][len(self.used_names) % len(self.name_pool['surname'])]
            given = ['ä¼Ÿ', 'å¼º', 'æ˜', 'æ´‹', 'å†›', 'ç£Š', 'åˆš', 'å‹‡'][len(self.used_names) % 8]
            name = surname + given
        else:
            name = available[0]
        
        self.used_names.add(name)
        return name
    
    def create_mapping(self, original_names: List[str]) -> Dict[str, str]:
        """åˆ›å»ºå§“åæ˜ å°„"""
        mapping = {}
        for orig_name in original_names:
            if orig_name not in mapping:
                new_name = self.generate_name()
                mapping[orig_name] = new_name
        self.name_mapping = mapping
        return mapping
    
    def replace_names(self, text: str) -> str:
        """æ›¿æ¢æ–‡æœ¬ä¸­çš„å§“å"""
        result = text
        # æŒ‰é•¿åº¦ä»é•¿åˆ°çŸ­æ’åºï¼Œé¿å…çŸ­åè¦†ç›–é•¿å
        sorted_names = sorted(self.name_mapping.items(), key=lambda x: len(x[0]), reverse=True)
        for orig, new in sorted_names:
            result = result.replace(orig, new)
        return result


class NovelRewriter:
    """å°è¯´æ”¹å†™ç±»ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    
    def __init__(self, input_file: str, output_file: Optional[str] = None, output_dir: str = "rewritten"):
        """
        åˆå§‹åŒ–æ”¹å†™å™¨
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            output_dir: è¾“å‡ºæ–‡ä»¶å¤¹åç§°ï¼Œé»˜è®¤ä¸º"rewritten"
        """
        self.input_file = input_file
        self.output_dir = output_dir
        
        # è·å–è¾“å…¥æ–‡ä»¶çš„ç›®å½•å’Œæ–‡ä»¶å
        input_dir = os.path.dirname(input_file)
        input_basename = os.path.basename(input_file)
        input_name, input_ext = os.path.splitext(input_basename)
        
        # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
        if input_dir:
            self.output_dir_path = os.path.join(input_dir, output_dir)
        else:
            self.output_dir_path = output_dir
        
        if not os.path.exists(self.output_dir_path):
            os.makedirs(self.output_dir_path)
            print(f"ğŸ“ åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹: {self.output_dir_path}/")
        
        # è®¾ç½®è¾“å‡ºæ–‡ä»¶è·¯å¾„
        if not output_file:
            output_basename = f"{input_name}_rewritten{input_ext}"
            self.output_file = os.path.join(self.output_dir_path, output_basename)
        else:
            if not os.path.dirname(output_file):
                self.output_file = os.path.join(self.output_dir_path, output_file)
            else:
                self.output_file = output_file
        
        self.content = ""
        self.metadata = {}
        self.analyzer = None
        self.name_mapper = CharacterNameMapper()
        self.ai_analyzer = None  # AIåˆ†æå™¨
        self.ai_analyzer = None  # AIåˆ†æå™¨
    
    def load_novel(self) -> bool:
        """åŠ è½½å°è¯´å†…å®¹"""
        try:
            with open(self.input_file, 'r', encoding='utf-8') as f:
                self.content = f.read()
            print(f"âœ… æˆåŠŸåŠ è½½å°è¯´: {self.input_file}")
            return True
        except Exception as e:
            print(f"âŒ åŠ è½½å¤±è´¥: {e}")
            return False
    
    def analyze_novel(self, use_ai: bool = False, ai_type: str = "openai", **ai_kwargs) -> bool:
        """
        åˆ†æå°è¯´å†…å®¹
        
        Args:
            use_ai: æ˜¯å¦ä½¿ç”¨AIåˆ†æ
            ai_type: AIç±»å‹ï¼ˆopenai/local/offlineï¼‰
            **ai_kwargs: AIç›¸å…³å‚æ•°
        """
        if not self.content:
            if not self.load_novel():
                return False
        
        print("\nğŸ“š å¼€å§‹åˆ†æå°è¯´å†…å®¹...")
        
        # å°è¯•ä½¿ç”¨AIåˆ†æ
        if use_ai and AI_AVAILABLE:
            try:
                self.ai_analyzer = AIAnalyzerFactory.create_analyzer(ai_type, **ai_kwargs)
                if self.ai_analyzer:
                    print("ğŸ¤– ä½¿ç”¨AIè¿›è¡Œæ·±åº¦åˆ†æ...")
                    
                    # ä½¿ç”¨AIåˆ†æäººç‰©
                    ai_characters = self.ai_analyzer.analyze_characters(self.content)
                    if ai_characters:
                        print(f"   AIè¯†åˆ«åˆ° {len(ai_characters)} ä¸ªäººç‰©")
                    
                    # ä½¿ç”¨AIåˆ†ææ•…äº‹è„‰ç»œ
                    ai_storyline = self.ai_analyzer.analyze_storyline(self.content)
                    if ai_storyline:
                        print(f"   AIåˆ†æå®Œæˆï¼š{ai_storyline.get('theme', 'æœªçŸ¥ä¸»é¢˜')}")
            except Exception as e:
                print(f"âš ï¸  AIåˆ†æå¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•: {e}")
                self.ai_analyzer = None
        
        # ä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•åˆ†æ
        if not self.analyzer:
            self.analyzer = NovelAnalyzer(self.content)
        
        # æå–äººç‰©
        characters = self.analyzer.extract_characters()
        
        # åˆå¹¶AIåˆ†æç»“æœ
        if use_ai and self.ai_analyzer:
            ai_characters = self.ai_analyzer.analyze_characters(self.content)
            if ai_characters:
                for name, info in ai_characters.items():
                    if name not in self.analyzer.characters:
                        self.analyzer.characters[name] = {
                            'name': name,
                            'count': self.content.count(name),
                            'role': info.get('role', 'é…è§’'),
                            'description': info.get('description', ''),
                            'importance': info.get('importance', 5)
                        }
        
        # åˆ†ææ•…äº‹è„‰ç»œ
        storyline = self.analyzer.analyze_storyline()
        
        # åˆ†ææƒ…èŠ‚ç»“æ„
        plot_structure = self.analyzer.analyze_plot_structure()
        
        # ç”Ÿæˆæ‘˜è¦
        summary = self.analyzer.generate_summary()
        
        print(f"\nğŸ“Š åˆ†æç»“æœ:")
        print(f"   æ€»ç« èŠ‚æ•°: {summary['total_chapters']}")
        print(f"   ä¸»è¦äººç‰©: {', '.join(summary['main_characters'][:5])}")
        print(f"   æ•…äº‹ç»“æ„: {summary['story_arc']}")
        
        return True
    
    def change_perspective(self, from_perspective: str = "ç¬¬ä¸€äººç§°", to_perspective: str = "ç¬¬ä¸‰äººç§°") -> str:
        """è½¬æ¢äººç§°è§†è§’"""
        if from_perspective == to_perspective:
            return self.content
        
        result = self.content
        
        if from_perspective == "ç¬¬ä¸€äººç§°" and to_perspective == "ç¬¬ä¸‰äººç§°":
            replacements = {
                r'\bæˆ‘\b': 'ä»–',
                r'\bæˆ‘çš„\b': 'ä»–çš„',
                r'\bæˆ‘ä»¬\b': 'ä»–ä»¬',
                r'\bæˆ‘ä»¬çš„\b': 'ä»–ä»¬çš„',
                r'\bè‡ªå·±\b': 'ä»–è‡ªå·±',
            }
            for pattern, replacement in replacements.items():
                result = re.sub(pattern, replacement, result)
        
        elif from_perspective == "ç¬¬ä¸‰äººç§°" and to_perspective == "ç¬¬ä¸€äººç§°":
            replacements = {
                r'\bä»–\b': 'æˆ‘',
                r'\bä»–çš„\b': 'æˆ‘çš„',
                r'\bä»–ä»¬\b': 'æˆ‘ä»¬',
                r'\bä»–ä»¬çš„\b': 'æˆ‘ä»¬çš„',
            }
            for pattern, replacement in replacements.items():
                result = re.sub(pattern, replacement, result)
        
        print(f"âœ… è§†è§’è½¬æ¢å®Œæˆ: {from_perspective} â†’ {to_perspective}")
        return result
    
    def _split_into_chapters(self, content: str) -> List[str]:
        """å°†å†…å®¹åˆ†å‰²æˆç« èŠ‚"""
        chapters = []
        
        # æŸ¥æ‰¾ç« èŠ‚æ ‡è®°
        chapter_pattern = r'ç¬¬\s*(\d+)\s*ç« [ï¼š:ï¼š]?\s*(.*?)\n'
        matches = list(re.finditer(chapter_pattern, content))
        
        if not matches:
            # å¦‚æœæ²¡æœ‰ç« èŠ‚æ ‡è®°ï¼Œè¿”å›æ•´ä¸ªå†…å®¹ä½œä¸ºä¸€ä¸ªç« èŠ‚
            return [content]
        
        for i, match in enumerate(matches):
            chapter_start = match.end()
            next_match = matches[i + 1] if i + 1 < len(matches) else None
            chapter_end = next_match.start() if next_match else len(content)
            
            chapter_text = content[chapter_start:chapter_end].strip()
            if chapter_text:
                chapters.append(chapter_text)
        
        return chapters if chapters else [content]
    
    def change_style(self, style: str = "ç°ä»£", use_ai: bool = False, 
                     ai_type: str = "tensorflow",
                     novel_context: Optional[Dict] = None,
                     chapter_context: Optional[str] = None,
                     **ai_kwargs) -> str:
        """
        ä¿®æ”¹è¯­è¨€é£æ ¼ï¼ˆå¢å¼ºç‰ˆï¼Œæ”¯æŒç»Ÿä¸€æ¥å£ï¼‰
        
        Args:
            style: ç›®æ ‡é£æ ¼
                åŸºç¡€é£æ ¼ï¼šç°ä»£/å¤å…¸/ç®€æ´/åä¸½/æ‚¬ç–‘/æµªæ¼«/å¹½é»˜/ä¸¥è‚ƒ
                æ‰©å±•é£æ ¼ï¼šç§‘å¹»/æ­¦ä¾ /é’æ˜¥/éƒ½å¸‚/å¤é£/è¯—åŒ–/å£è¯­/æ­£å¼/ç½‘ç»œ/æ–‡è‰º
            use_ai: æ˜¯å¦ä½¿ç”¨AIè¿›è¡Œæ”¹å†™
            ai_type: AIç±»å‹ (openai/local/tensorflow)
            **ai_kwargs: AIç›¸å…³å‚æ•°
        """
        # ä¼˜å…ˆä½¿ç”¨ç»Ÿä¸€æ¥å£ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if use_ai and INTEGRATION_AVAILABLE:
            try:
                from scripts.ai.integration import UnifiedRewriter
                model_path = ai_kwargs.get('model_path', 'models/text_rewriter_model')
                rewriter = UnifiedRewriter(
                    ai_type=ai_type,
                    ai_model_path=model_path,
                    use_hybrid=True
                )
                
                # æå–ä¸Šä¸‹æ–‡ï¼ˆå¢å¼ºç‰ˆï¼‰
                context = chapter_context if chapter_context else ""
                if not context and self.analyzer:
                    summary = self.analyzer.generate_summary()
                    context = f"æ•…äº‹ä¸»é¢˜ï¼š{summary.get('story_arc', '')}ï¼Œä¸»è¦äººç‰©ï¼š{', '.join(summary.get('main_characters', [])[:5])}"
                
                # ä½¿ç”¨ç»Ÿä¸€æ¥å£æ”¹å†™ï¼ˆä¼ å…¥å°è¯´ä¸Šä¸‹æ–‡ï¼‰
                result = rewriter.rewrite(
                    self.content,
                    style=style,
                    context=context,
                    use_ai=True,
                    novel_context=novel_context,
                    chapter_num=0
                )
                
                if result and result != self.content:
                    print(f"âœ… ä½¿ç”¨ç»Ÿä¸€æ¥å£å®Œæˆé£æ ¼è½¬æ¢: {style}")
                    return result
            except Exception as e:
                print(f"âš ï¸  ç»Ÿä¸€æ¥å£å¤±è´¥ï¼Œé™çº§åˆ°ä¼ ç»Ÿæ–¹æ³•: {e}")
        
        # å¦‚æœä½¿ç”¨AIä¸”AIåˆ†æå™¨å¯ç”¨ï¼Œä½¿ç”¨AIæ”¹å†™ï¼ˆæ·±åº¦å­¦ä¹ ä¼˜åŒ–ç‰ˆï¼‰
        if use_ai and self.ai_analyzer:
            print(f"ğŸ¤– ä½¿ç”¨æ·±åº¦å­¦ä¹ AIè¿›è¡Œé£æ ¼è½¬æ¢å’Œè¯­è¨€ä¼˜åŒ–: {style}")
            try:
                # æ™ºèƒ½åˆ†æ®µå¤„ç†ï¼ˆä¿æŒä¸Šä¸‹æ–‡è¿è´¯ï¼‰
                result_parts = []
                chunk_size = 3000  # å¢åŠ å¤„ç†é•¿åº¦ï¼Œä¿æŒæ›´å¤šä¸Šä¸‹æ–‡
                total_chunks = (len(self.content) + chunk_size - 1) // chunk_size
                
                # æå–æ•´ä½“ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆç”¨äºå¸®åŠ©AIç†è§£ï¼‰
                context_summary = ""
                if self.analyzer:
                    summary = self.analyzer.generate_summary()
                    context_summary = f"æ•…äº‹ä¸»é¢˜ï¼š{summary.get('story_arc', '')}ï¼Œä¸»è¦äººç‰©ï¼š{', '.join(summary.get('main_characters', [])[:5])}"
                
                for i in range(0, len(self.content), chunk_size):
                    # è·å–å½“å‰å—
                    chunk = self.content[i:i+chunk_size]
                    
                    # è·å–å‰ä¸€å—çš„ç»“å°¾ï¼ˆä½œä¸ºä¸Šä¸‹æ–‡ï¼‰
                    prev_context = ""
                    if i > 0:
                        prev_start = max(0, i - 500)  # å‰500å­—ç¬¦ä½œä¸ºä¸Šä¸‹æ–‡
                        prev_context = self.content[prev_start:i]
                    
                    # è·å–ä¸‹ä¸€å—çš„å¼€å¤´ï¼ˆä½œä¸ºä¸Šä¸‹æ–‡ï¼‰
                    next_context = ""
                    if i + chunk_size < len(self.content):
                        next_end = min(len(self.content), i + chunk_size + 200)  # å200å­—ç¬¦ä½œä¸ºä¸Šä¸‹æ–‡
                        next_context = self.content[i+chunk_size:next_end]
                    
                    # æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡
                    full_context = f"{prev_context}\n\n[å½“å‰æ–‡æœ¬]\n\n{chunk}\n\n[åç»­æ–‡æœ¬é¢„è§ˆ]\n\n{next_context}"
                    if context_summary:
                        full_context = f"{context_summary}\n\n{full_context}"
                    
                    # ä½¿ç”¨AIæ”¹å†™ï¼ˆä¼ å…¥ä¸Šä¸‹æ–‡ï¼‰
                    rewritten_chunk = self.ai_analyzer.rewrite_text(
                        chunk, 
                        style, 
                        context=full_context
                    )
                    
                    result_parts.append(rewritten_chunk)
                    current_chunk = (i // chunk_size) + 1
                    print(f"   ğŸ¤– AIå¤„ç†è¿›åº¦: {current_chunk}/{total_chunks} ({current_chunk*100//total_chunks}%)")
                
                result = ''.join(result_parts)
                print(f"âœ… æ·±åº¦å­¦ä¹ AIé£æ ¼è½¬æ¢å®Œæˆ: {style}")
                return result
            except Exception as e:
                print(f"âš ï¸  AIæ”¹å†™å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•: {e}")
                import traceback
                traceback.print_exc()
        
        # ä¼ ç»Ÿæ–¹æ³• - ä¼˜å…ˆä½¿ç”¨è‡ªç„¶æ”¹å†™å™¨
        if NATURAL_REWRITER_AVAILABLE and style in ['éƒ½å¸‚', 'å¹½é»˜', 'éƒ½å¸‚å¹½é»˜', 'éƒ½å¸‚+å¹½é»˜', 'éƒ½å¸‚ã€å¹½é»˜']:
            print(f"âœ¨ ä½¿ç”¨æ™ºèƒ½æ–‡æœ¬å¤„ç†å™¨è¿›è¡Œè‡ªç„¶æ”¹å†™...")
            try:
                natural_rewriter = NaturalStyleRewriter()
                result = natural_rewriter.rewrite_naturally(self.content, style)
                print(f"âœ… è‡ªç„¶é£æ ¼è½¬æ¢å®Œæˆ: {style}")
                return result
            except Exception as e:
                print(f"âš ï¸  æ™ºèƒ½æ”¹å†™å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•: {e}")
        
        # ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¤‡ç”¨ï¼‰
        result = self.content
        
        if style == "ç®€æ´":
            # ç®€åŒ–è¡¨è¾¾
            result = re.sub(r'ï¼Œ[^ï¼Œã€‚ï¼ï¼Ÿ]{0,5}ï¼Œ', 'ï¼Œ', result)
            result = re.sub(r'ã€‚\s*ã€‚', 'ã€‚', result)
            result = re.sub(r'[ï¼Œã€‚ï¼ï¼Ÿ]{2,}', lambda m: m.group(0)[0], result)
        
        elif style == "åä¸½":
            # å¢åŠ ä¿®é¥°è¯
            result = re.sub(r'(\w+)([ï¼Œã€‚ï¼ï¼Ÿ])', r'\1ï¼Œ\2', result)
            # æ·»åŠ å½¢å®¹è¯
            result = re.sub(r'(æ˜¯)([^ï¼Œã€‚ï¼ï¼Ÿ]+)', r'\1å¦‚æ­¤çš„\2', result)
        
        elif style == "å¤å…¸":
            # è½¬æ¢ä¸ºå¤å…¸é£æ ¼
            replacements = {
                r'çš„': 'ä¹‹',
                r'äº†': 'çŸ£',
                r'å—': 'ä¹',
                r'å‘¢': 'ç„‰',
            }
            for pattern, replacement in replacements.items():
                result = re.sub(pattern, replacement, result)
        
        elif style == "æ‚¬ç–‘":
            # å¢åŠ æ‚¬ç–‘æ°›å›´
            result = re.sub(r'([ã€‚ï¼ï¼Ÿ])\s*', r'\1\n\nã€æ°”æ°›ç´§å¼ ã€‘\n\n', result[:1000]) + result[1000:]
        
        elif style == "æµªæ¼«":
            # å¢åŠ æµªæ¼«å…ƒç´ 
            result = re.sub(r'(è¯´|é“)([^ï¼Œã€‚ï¼ï¼Ÿ]+)', r'\1ï¼Œçœ¼ä¸­é—ªçƒç€æ¸©æŸ”çš„å…‰èŠ’\2', result)
        
        elif style == "å¹½é»˜":
            # å¢åŠ å¹½é»˜å…ƒç´ 
            result = re.sub(r'([ã€‚ï¼ï¼Ÿ])\s*([^ï¼Œã€‚ï¼ï¼Ÿ]{0,20})', r'\1\nã€æœ‰è¶£çš„æ˜¯ã€‘\2', result[:500]) + result[500:]
        
        elif style == "ä¸¥è‚ƒ":
            # ä¸¥è‚ƒé£æ ¼
            result = re.sub(r'([ï¼Œã€‚ï¼ï¼Ÿ])\s*', r'\1\n', result)
        
        elif style == "ç§‘å¹»":
            # ç§‘å¹»é£æ ¼ï¼šå¢åŠ ç§‘æŠ€æ„Ÿã€æœªæ¥æ„Ÿ
            result = re.sub(r'(è¯´|é“)', r'é€šè¿‡é€šè®¯å™¨è¯´é“', result[:500]) + result[500:]
            result = re.sub(r'(çœ‹|è§‚å¯Ÿ)', r'é€šè¿‡æ‰«æä»ªè§‚å¯Ÿ', result[:500]) + result[500:]
        
        elif style == "æ­¦ä¾ ":
            # æ­¦ä¾ é£æ ¼ï¼šå¢åŠ æ­¦ä¾ å…ƒç´ 
            result = re.sub(r'(èµ°|æ¥|å»)', r'æ–½å±•è½»åŠŸ\1', result[:500]) + result[500:]
            result = re.sub(r'(è¯´|é“)', r'æŠ±æ‹³è¯´é“', result[:300]) + result[300:]
        
        elif style == "é’æ˜¥":
            # é’æ˜¥é£æ ¼ï¼šè½»æ¾æ´»æ³¼
            result = re.sub(r'([ã€‚ï¼ï¼Ÿ])\s*', r'\1\n\n', result)
            result = re.sub(r'(å¾ˆ|éå¸¸)', r'è¶…çº§', result[:1000]) + result[1000:]
        
        elif style == "éƒ½å¸‚":
            # éƒ½å¸‚é£æ ¼ï¼šç°ä»£éƒ½å¸‚ç”Ÿæ´»ï¼Œå¢åŠ éƒ½å¸‚åœºæ™¯æå†™
            # é€‚åº¦å¢åŠ éƒ½å¸‚å…ƒç´ ï¼Œé¿å…è¿‡åº¦æ›¿æ¢
            # åœ¨å…³é”®ä½ç½®æ·»åŠ éƒ½å¸‚åœºæ™¯
            result = re.sub(r'(è¯´|é“)([^ï¼Œã€‚ï¼ï¼Ÿ]{5,30}[ï¼Œã€‚ï¼ï¼Ÿ])', 
                          lambda m: f"{m.group(1)}ï¼Œåœ¨éƒ½å¸‚çš„å’–å•¡å…é‡Œ{m.group(2)}" if random.random() < 0.1 else m.group(0), 
                          result)
            # å¢åŠ éƒ½å¸‚æ°›å›´è¯æ±‡ï¼ˆé€‚åº¦ï¼‰
            result = re.sub(r'\b(åŸå¸‚|åœ°æ–¹)\b', r'éƒ½å¸‚', result[:5000]) + result[5000:]
            # å¢åŠ ç°ä»£éƒ½å¸‚ç”Ÿæ´»å…ƒç´ 
            result = re.sub(r'(èµ°|æ¥|å»)([^ï¼Œã€‚ï¼ï¼Ÿ]{0,15}[ï¼Œã€‚ï¼ï¼Ÿ])', 
                          lambda m: f"ç©¿æ¢­åœ¨éƒ½å¸‚è¡—é“ä¸Š{m.group(1)}{m.group(2)}" if random.random() < 0.05 else m.group(0), 
                          result)
        
        elif style == "å¹½é»˜":
            # å¹½é»˜é£æ ¼ï¼šå¹½é»˜é£è¶£çš„è¡¨è¾¾ï¼Œå¢åŠ å¹½é»˜å…ƒç´ 
            # åœ¨å¯¹è¯ä¸­é€‚åº¦å¢åŠ å¹½é»˜æ„Ÿï¼ˆé¿å…è¿‡åº¦ï¼‰
            result = re.sub(r'(".*?")([ï¼Œã€‚ï¼ï¼Ÿ])', 
                          lambda m: f"{m.group(1)}ï¼Œå“ˆå“ˆ{m.group(2)}" if random.random() < 0.15 else m.group(0), 
                          result)
            # ä½¿ç”¨è½»æ¾å¹½é»˜çš„è¯æ±‡
            result = re.sub(r'\b(å¾ˆ|éå¸¸)\b', r'è¶…çº§', result[:3000]) + result[3000:]
            result = re.sub(r'\b(å¥½)\b', r'æ£’æäº†', result[:2000]) + result[2000:]
            result = re.sub(r'\b(è¯´|é“)\b', 
                          lambda m: 'ç¬‘ç€è¯´' if random.random() < 0.1 else m.group(0), 
                          result)
            # é€‚åº¦å¢åŠ å¹½é»˜æè¿°ï¼ˆæ¯æ®µæœ€å¤šä¸€ä¸ªï¼‰
            lines = result.split('\n')
            new_lines = []
            humor_added = False
            for line in lines:
                if not humor_added and len(line) > 20 and random.random() < 0.05:
                    new_lines.append(line + ' ã€æœ‰è¶£çš„æ˜¯ã€‘')
                    humor_added = True
                else:
                    new_lines.append(line)
                if 'ã€‚' in line or 'ï¼' in line or 'ï¼Ÿ' in line:
                    humor_added = False
            result = '\n'.join(new_lines)
        
        elif style == "éƒ½å¸‚å¹½é»˜" or style == "éƒ½å¸‚+å¹½é»˜" or style == "éƒ½å¸‚ã€å¹½é»˜":
            # ç»„åˆé£æ ¼ï¼šéƒ½å¸‚+å¹½é»˜ï¼Œæ—¢æœ‰éƒ½å¸‚æ„Ÿåˆæœ‰å¹½é»˜æ„Ÿ
            # å…ˆåº”ç”¨éƒ½å¸‚å…ƒç´ ï¼ˆé€‚åº¦ï¼‰
            result = re.sub(r'\b(åŸå¸‚|åœ°æ–¹)\b', r'éƒ½å¸‚', result[:5000]) + result[5000:]
            # åœ¨å…³é”®ä½ç½®æ·»åŠ éƒ½å¸‚åœºæ™¯
            result = re.sub(r'(è¯´|é“)([^ï¼Œã€‚ï¼ï¼Ÿ]{5,30}[ï¼Œã€‚ï¼ï¼Ÿ])', 
                          lambda m: f"{m.group(1)}ï¼Œåœ¨éƒ½å¸‚çš„å’–å•¡å…é‡Œç¬‘ç€è¯´{m.group(2)}" if random.random() < 0.08 else m.group(0), 
                          result)
            # åº”ç”¨å¹½é»˜å…ƒç´ 
            result = re.sub(r'\b(å¾ˆ|éå¸¸)\b', r'è¶…çº§', result[:3000]) + result[3000:]
            result = re.sub(r'\b(å¥½)\b', r'æ£’æäº†', result[:2000]) + result[2000:]
            result = re.sub(r'(".*?")([ï¼Œã€‚ï¼ï¼Ÿ])', 
                          lambda m: f"{m.group(1)}ï¼Œå“ˆå“ˆ{m.group(2)}" if random.random() < 0.12 else m.group(0), 
                          result)
            # é€‚åº¦å¢åŠ å¹½é»˜æè¿°
            lines = result.split('\n')
            new_lines = []
            humor_added = False
            for line in lines:
                if not humor_added and len(line) > 30 and random.random() < 0.03:
                    new_lines.append(line + ' ã€åœ¨éƒ½å¸‚çš„å–§åš£ä¸­ï¼Œæœ‰è¶£çš„æ˜¯ã€‘')
                    humor_added = True
                else:
                    new_lines.append(line)
                if 'ã€‚' in line or 'ï¼' in line or 'ï¼Ÿ' in line:
                    humor_added = False
            result = '\n'.join(new_lines)
        
        elif style == "å¤é£":
            # å¤é£é£æ ¼ï¼šå¤ä»£æ–‡é›…
            replacements = {
                r'çš„': 'ä¹‹',
                r'äº†': 'çŸ£',
                r'å—': 'ä¹',
                r'å‘¢': 'ç„‰',
                r'è¯´': 'æ›°',
                r'çœ‹': 'è§‚',
            }
            for pattern, replacement in replacements.items():
                result = re.sub(pattern, replacement, result)
        
        elif style == "è¯—åŒ–":
            # è¯—åŒ–é£æ ¼ï¼šå¢åŠ è¯—æ„
            result = re.sub(r'([ã€‚ï¼ï¼Ÿ])\s*', r'\1\n\n', result)
            result = re.sub(r'(\w+)([ï¼Œã€‚ï¼ï¼Ÿ])', r'\1ï¼Œå¦‚è¯—å¦‚ç”»\2', result[:500]) + result[500:]
        
        elif style == "å£è¯­":
            # å£è¯­åŒ–é£æ ¼ï¼šæ›´è´´è¿‘æ—¥å¸¸å¯¹è¯
            result = re.sub(r'([ï¼Œã€‚ï¼ï¼Ÿ])\s*', r'\1 ', result)
            result = re.sub(r'(å¾ˆ|éå¸¸)', r'æŒº', result[:1000]) + result[1000:]
        
        elif style == "æ­£å¼":
            # æ­£å¼é£æ ¼ï¼šæ­£å¼ä¹¦é¢è¯­
            result = re.sub(r'(è¯´|é“)', r'è¡¨ç¤º', result)
            result = re.sub(r'(çœ‹|è§‚å¯Ÿ)', r'å®¡è§†', result[:500]) + result[500:]
        
        elif style == "ç½‘ç»œ":
            # ç½‘ç»œé£æ ¼ï¼šç½‘ç»œç”¨è¯­
            result = re.sub(r'(å¾ˆ|éå¸¸)', r'è¶…', result[:1000]) + result[1000:]
            result = re.sub(r'(å¥½)', r'æ£’', result[:500]) + result[500:]
        
        elif style == "æ–‡è‰º":
            # æ–‡è‰ºé£æ ¼ï¼šæ–‡è‰ºèŒƒ
            result = re.sub(r'([ã€‚ï¼ï¼Ÿ])\s*', r'\1\n\n', result)
            result = re.sub(r'(è¯´|é“)', r'è½»å£°è¯´é“', result[:500]) + result[500:]
        
        elif style == "ç°ä»£":
            # ç°ä»£é£æ ¼ï¼šä¿æŒåŸæ ·æˆ–è½»å¾®è°ƒæ•´
            pass  # ç°ä»£é£æ ¼é€šå¸¸ä¸éœ€è¦å¤ªå¤šæ”¹åŠ¨
        
        print(f"âœ… é£æ ¼è½¬æ¢å®Œæˆ: {style}")
        return result
    
    def replace_character_names(self, replace_names: bool = True) -> str:
        """æ›¿æ¢äººç‰©å§“å"""
        if not replace_names:
            return self.content
        
        if not self.analyzer:
            if not self.analyze_novel():
                return self.content
        
        # è·å–ä¸»è¦äººç‰©åˆ—è¡¨
        if not self.analyzer.characters:
            return self.content
        
        character_names = list(self.analyzer.characters.keys())
        
        # åˆ›å»ºå§“åæ˜ å°„
        name_mapping = self.name_mapper.create_mapping(character_names)
        
        # æ›¿æ¢å§“å
        result = self.name_mapper.replace_names(self.content)
        
        print(f"âœ… å§“åæ›¿æ¢å®Œæˆï¼Œå…±æ›¿æ¢ {len(name_mapping)} ä¸ªäººç‰©")
        print(f"   å§“åæ˜ å°„: {dict(list(name_mapping.items())[:5])}...")
        
        return result
    
    def rewrite(self, perspective: Optional[str] = None, 
                style: Optional[str] = None, 
                replace_names: bool = False,
                analyze: bool = True,
                use_ai: bool = False,
                ai_type: str = "tensorflow",
                maintain_consistency: bool = True,
                **ai_kwargs) -> bool:
        """
        æ‰§è¡Œæ”¹å†™
        
        Args:
            perspective: ç›®æ ‡è§†è§’ï¼ˆå¯é€‰ï¼‰
            style: ç›®æ ‡é£æ ¼ï¼ˆå¯é€‰ï¼‰
            replace_names: æ˜¯å¦æ›¿æ¢äººç‰©å§“å
            analyze: æ˜¯å¦å…ˆåˆ†æå°è¯´
        
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        if not self.content:
            if not self.load_novel():
                return False
        
        # åˆ†æå°è¯´ï¼ˆå¦‚æœéœ€è¦ï¼‰
        novel_context = None
        if analyze:
            if not self.analyze_novel(use_ai=use_ai, ai_type=ai_type, **ai_kwargs):
                print("âš ï¸  åˆ†æå¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨åŸºç¡€æ”¹å†™åŠŸèƒ½")
            
            # å¦‚æœå¯ç”¨ä¸€è‡´æ€§æ£€æŸ¥ï¼Œæ„å»ºå°è¯´ä¸Šä¸‹æ–‡
            if maintain_consistency:
                try:
                    from scripts.ai.context_manager import NovelContextManager
                    context_manager = NovelContextManager()
                    novel_context = context_manager.build_context(self.content)
                    print("âœ… å·²æ„å»ºå°è¯´ä¸Šä¸‹æ–‡ï¼Œå°†ç”¨äºä¿æŒé€»è¾‘ä¸€è‡´æ€§")
                except Exception as e:
                    print(f"âš ï¸  ä¸Šä¸‹æ–‡æ„å»ºå¤±è´¥: {e}")
        
        result = self.content
        
        # å¦‚æœå†…å®¹å¾ˆé•¿ï¼ŒæŒ‰ç« èŠ‚å¤„ç†ä»¥ä¿æŒä¸€è‡´æ€§
        chapters = self._split_into_chapters(result)
        if len(chapters) > 1 and maintain_consistency:
            print(f"ğŸ“š æ£€æµ‹åˆ° {len(chapters)} ä¸ªç« èŠ‚ï¼Œå°†æŒ‰ç« èŠ‚å¤„ç†ä»¥ä¿æŒé€»è¾‘ä¸€è‡´æ€§...")
            rewritten_chapters = []
            
            for i, chapter in enumerate(chapters):
                print(f"   å¤„ç†ç¬¬ {i+1}/{len(chapters)} ç« ...")
                chapter_result = chapter
                
                # æ›¿æ¢å§“å
                if replace_names:
                    chapter_result = self.replace_character_names(replace_names=True)
                
                # è½¬æ¢è§†è§’
                if perspective:
                    chapter_result = self.change_perspective(to_perspective=perspective)
                
                # ä¿®æ”¹é£æ ¼ï¼ˆä½¿ç”¨ç»Ÿä¸€æ¥å£ï¼Œä¼ å…¥ç« èŠ‚ä¸Šä¸‹æ–‡ï¼‰
                if style:
                    chapter_context = None
                    if novel_context:
                        # è·å–å½“å‰ç« èŠ‚çš„ä¸Šä¸‹æ–‡
                        try:
                            from scripts.ai.context_manager import NovelContextManager
                            context_manager = NovelContextManager()
                            chapter_context = context_manager.get_context_for_rewrite(
                                chapter_result,
                                chapter_num=i+1
                            )
                        except:
                            pass
                    
                    chapter_result = self.change_style(
                        style=style, 
                        use_ai=use_ai,
                        ai_type=ai_type,
                        novel_context=novel_context,
                        chapter_context=chapter_context,
                        **ai_kwargs
                    )
                
                rewritten_chapters.append(chapter_result)
            
            result = '\n\n'.join(rewritten_chapters)
            
            # éªŒè¯æ•´æœ¬ä¹¦çš„ä¸€è‡´æ€§
            if maintain_consistency:
                try:
                    from scripts.ai.consistency_checker import ConsistencyChecker
                    checker = ConsistencyChecker()
                    checker.analyze_novel(self.content)
                    is_consistent, issues = checker.validate_rewritten_novel(
                        chapters, rewritten_chapters
                    )
                    if not is_consistent:
                        print(f"âš ï¸  æ•´æœ¬ä¹¦å­˜åœ¨é€»è¾‘ä¸€è‡´æ€§é—®é¢˜: {len(issues)} ä¸ªé—®é¢˜")
                        for issue in issues[:5]:
                            print(f"    - {issue}")
                except Exception as e:
                    print(f"âš ï¸  ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {e}")
        else:
            # å•ç« èŠ‚æˆ–çŸ­æ–‡æœ¬å¤„ç†
            # æ›¿æ¢å§“å
            if replace_names:
                result = self.replace_character_names(replace_names=True)
            
            # è½¬æ¢è§†è§’
            if perspective:
                result = self.change_perspective(to_perspective=perspective)
            
            # ä¿®æ”¹é£æ ¼ï¼ˆä½¿ç”¨ç»Ÿä¸€æ¥å£ï¼‰
            if style:
                result = self.change_style(
                    style=style, 
                    use_ai=use_ai,
                    ai_type=ai_type,
                    novel_context=novel_context,
                    **ai_kwargs
                )
        
        # ä¿å­˜ç»“æœ
        try:
            with open(self.output_file, 'w', encoding='utf-8') as f:
                f.write(result)
            print(f"\nâœ… æ”¹å†™å®Œæˆï¼Œå·²ä¿å­˜åˆ°: {self.output_file}")
            
            # ä¿å­˜åˆ†ææŠ¥å‘Šï¼ˆå¦‚æœè¿›è¡Œäº†åˆ†æï¼‰
            if self.analyzer:
                report_file = os.path.splitext(self.output_file)[0] + '_analysis.json'
                report = {
                    'characters': {name: {'count': info['count'], 'role': info['role']} 
                                 for name, info in self.analyzer.characters.items()},
                    'summary': self.analyzer.generate_summary(),
                    'name_mapping': self.name_mapper.name_mapping if replace_names else {}
                }
                with open(report_file, 'w', encoding='utf-8') as f:
                    json.dump(report, f, ensure_ascii=False, indent=2)
                print(f"ğŸ“Š åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
            
            return True
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python3 rewrite_novel.py <è¾“å…¥æ–‡ä»¶> [è¾“å‡ºæ–‡ä»¶] [é€‰é¡¹]")
        print("\nåŸºç¡€é€‰é¡¹:")
        print("  --perspective=ç¬¬ä¸€äººç§°/ç¬¬ä¸‰äººç§°  # è½¬æ¢äººç§°è§†è§’")
        print("  --style=é£æ ¼åç§°  # ä¿®æ”¹é£æ ¼")
        print("    åŸºç¡€é£æ ¼ï¼šç°ä»£/å¤å…¸/ç®€æ´/åä¸½/æ‚¬ç–‘/æµªæ¼«/å¹½é»˜/ä¸¥è‚ƒ")
        print("    æ‰©å±•é£æ ¼ï¼šç§‘å¹»/æ­¦ä¾ /é’æ˜¥/éƒ½å¸‚/å¤é£/è¯—åŒ–/å£è¯­/æ­£å¼/ç½‘ç»œ/æ–‡è‰º")
        print("  --replace-names                    # æ›¿æ¢äººç‰©å§“å")
        print("  --no-analyze                      # è·³è¿‡å°è¯´åˆ†æï¼ˆæ›´å¿«ä½†åŠŸèƒ½å—é™ï¼‰")
        print("  --output-dir=rewritten            # è¾“å‡ºæ–‡ä»¶å¤¹åç§°")
        print("\nAIé€‰é¡¹ï¼ˆéœ€è¦é…ç½®APIå¯†é’¥ï¼‰:")
        print("  --use-ai                          # å¯ç”¨AIåˆ†æï¼ˆéœ€è¦OPENAI_API_KEYç¯å¢ƒå˜é‡ï¼‰")
        print("  --ai-type=openai/local/tensorflow  # AIç±»å‹")
        print("                                     #   openai: OpenAI APIï¼ˆéœ€è¦APIå¯†é’¥ï¼‰")
        print("                                     #   local: æœ¬åœ°LLMï¼ˆOllamaç­‰ï¼‰")
        print("                                     #   tensorflow: TensorFlowæœ¬åœ°æ¨¡å‹ï¼ˆæ¨èï¼Œå®Œå…¨æœ¬åœ°ï¼‰")
        print("  --ai-model=gpt-4                  # AIæ¨¡å‹åç§°ï¼ˆä»…openaiï¼Œæ¨ègpt-4ï¼‰")
        print("  --ai-model-path=models/text_rewriter  # TensorFlowæ¨¡å‹è·¯å¾„ï¼ˆä»…tensorflowï¼‰")
        print("  --ai-base-url=http://localhost:11434  # æœ¬åœ°LLMæœåŠ¡åœ°å€ï¼ˆä»…localï¼‰")
        print("\nç¤ºä¾‹:")
        print("  # ä¼ ç»Ÿæ–¹æ³•")
        print("  python3 rewrite_novel.py novel.txt --perspective=ç¬¬ä¸‰äººç§° --style=ç®€æ´")
        print("  # ä½¿ç”¨OpenAI AIåˆ†æ")
        print("  python3 rewrite_novel.py novel.txt --use-ai --ai-type=openai --style=æ‚¬ç–‘")
        print("  # ä½¿ç”¨æœ¬åœ°LLM")
        print("  python3 rewrite_novel.py novel.txt --use-ai --ai-type=local --ai-model=llama2")
        print("\nè¯´æ˜:")
        print("  - æ”¹å†™åçš„æ–‡ä»¶ä¼šä¿å­˜åœ¨è¾“å…¥æ–‡ä»¶æ‰€åœ¨ç›®å½•çš„ rewritten/ æ–‡ä»¶å¤¹ä¸­")
        print("  - ä½¿ç”¨AIéœ€è¦è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡æˆ–é…ç½®æœ¬åœ°LLMæœåŠ¡")
        sys.exit(1)
    
    input_file = sys.argv[1]
    output_file = None
    perspective = None
    style = None
    replace_names = False
    analyze = True
    output_dir = "rewritten"
    use_ai = False
    ai_type = "openai"
    ai_kwargs = {}
    
    # è§£æå‚æ•°
    for arg in sys.argv[2:]:
        if arg.startswith('--perspective='):
            perspective = arg.split('=')[1]
        elif arg.startswith('--style='):
            style = arg.split('=')[1]
        elif arg == '--replace-names':
            replace_names = True
        elif arg == '--no-analyze':
            analyze = False
        elif arg == '--use-ai':
            use_ai = True
        elif arg.startswith('--ai-type='):
            ai_type = arg.split('=')[1]
        elif arg.startswith('--ai-model='):
            ai_kwargs['model'] = arg.split('=')[1]
        elif arg.startswith('--ai-model-path='):
            ai_kwargs['model_path'] = arg.split('=')[1]
        elif arg.startswith('--ai-base-url='):
            ai_kwargs['base_url'] = arg.split('=')[1]
        elif arg.startswith('--output-dir='):
            output_dir = arg.split('=')[1]
        elif not arg.startswith('--'):
            output_file = arg
    
    rewriter = NovelRewriter(input_file, output_file, output_dir=output_dir)
    
    if rewriter.rewrite(perspective=perspective, style=style, 
                       replace_names=replace_names, analyze=analyze,
                       use_ai=use_ai, ai_type=ai_type, **ai_kwargs):
        print("\nâœ… æ”¹å†™å®Œæˆï¼")
        print(f"ğŸ“ æ–‡ä»¶å·²ä¿å­˜åˆ°: {rewriter.output_file}")
    else:
        print("\nâŒ æ”¹å†™å¤±è´¥ï¼")
        sys.exit(1)


if __name__ == '__main__':
    main()
