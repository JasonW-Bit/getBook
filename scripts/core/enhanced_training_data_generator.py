#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆè®­ç»ƒæ•°æ®ç”Ÿæˆå™¨
ä»ç»“æ„åŒ–æ•°æ®ç”ŸæˆåŒ…å«äººç‰©æ€§æ ¼ã€é£æ ¼ã€è¯­æ°”ç­‰ä¸°å¯Œä¿¡æ¯çš„è®­ç»ƒæ•°æ®
"""

import os
import json
from typing import List, Dict, Optional
from pathlib import Path
from .intelligent_analyzer import IntelligentAnalyzer


class EnhancedTrainingDataGenerator:
    """å¢å¼ºç‰ˆè®­ç»ƒæ•°æ®ç”Ÿæˆå™¨ - ä½¿ç”¨ç»“æ„åŒ–æ•°æ®ç”Ÿæˆä¸°å¯Œçš„è®­ç»ƒæ ·æœ¬"""
    
    def __init__(self, output_dir: str = "data/training"):
        """
        åˆå§‹åŒ–ç”Ÿæˆå™¨
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
        """
        self.output_dir = output_dir
        self.structured_dir = os.path.join(output_dir, 'structured')
        self.processed_dir = os.path.join(output_dir, 'processed')
        self.analyzer = IntelligentAnalyzer()
        
        os.makedirs(self.processed_dir, exist_ok=True)
    
    def generate_from_structured_data(self, use_ai: bool = False) -> Optional[str]:
        """
        ä»ç»“æ„åŒ–æ•°æ®ç”Ÿæˆè®­ç»ƒæ•°æ®
        
        Args:
            use_ai: æ˜¯å¦ä½¿ç”¨AIç”Ÿæˆæ”¹å†™æ ·æœ¬
        
        Returns:
            è®­ç»ƒæ•°æ®æ–‡ä»¶è·¯å¾„
        """
        print("\nğŸ“ ä»ç»“æ„åŒ–æ•°æ®ç”Ÿæˆè®­ç»ƒæ ·æœ¬...")
        
        training_samples = []
        
        # æŸ¥æ‰¾æ‰€æœ‰ç»“æ„åŒ–æ•°æ®æ–‡ä»¶
        if not os.path.exists(self.structured_dir):
            print(f"  âŒ ç»“æ„åŒ–æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.structured_dir}")
            return None
        
        structured_files = [
            f for f in os.listdir(self.structured_dir)
            if f.endswith('_structured.json')
        ]
        
        if not structured_files:
            print(f"  âŒ æœªæ‰¾åˆ°ç»“æ„åŒ–æ•°æ®æ–‡ä»¶")
            return None
        
        print(f"  æ‰¾åˆ° {len(structured_files)} ä¸ªç»“æ„åŒ–æ•°æ®æ–‡ä»¶")
        
        # å¤„ç†æ¯ä¸ªç»“æ„åŒ–æ–‡ä»¶
        for struct_file in structured_files:
            struct_path = os.path.join(self.structured_dir, struct_file)
            
            try:
                with open(struct_path, 'r', encoding='utf-8') as f:
                    structured_data = json.load(f)
                
                # ä»ç»“æ„åŒ–æ•°æ®ç”Ÿæˆè®­ç»ƒæ ·æœ¬
                samples = self._generate_samples_from_structured(structured_data, use_ai)
                training_samples.extend(samples)
                
                print(f"    âœ… {Path(struct_file).stem}: {len(samples)} ä¸ªæ ·æœ¬")
                
            except Exception as e:
                print(f"    âš ï¸  å¤„ç† {struct_file} å¤±è´¥: {e}")
                continue
        
        if not training_samples:
            print(f"\nâŒ æœªç”Ÿæˆä»»ä½•è®­ç»ƒæ ·æœ¬")
            return None
        
        # æ•°æ®éªŒè¯
        print(f"\nğŸ” éªŒè¯è®­ç»ƒæ•°æ®...")
        valid_samples = self._validate_samples(training_samples)
        
        if not valid_samples:
            print(f"âŒ éªŒè¯å¤±è´¥: æ²¡æœ‰æœ‰æ•ˆæ ·æœ¬")
            return None
        
        print(f"  æœ‰æ•ˆæ ·æœ¬: {len(valid_samples)}/{len(training_samples)}")
        
        # ä¿å­˜è®­ç»ƒæ•°æ®
        training_file = self._save_training_data(valid_samples)
        
        return training_file
    
    def _generate_samples_from_structured(self, structured_data: Dict, use_ai: bool) -> List[Dict]:
        """
        ä»ç»“æ„åŒ–æ•°æ®ç”Ÿæˆè®­ç»ƒæ ·æœ¬
        
        Args:
            structured_data: ç»“æ„åŒ–æ•°æ®
            use_ai: æ˜¯å¦ä½¿ç”¨AI
        
        Returns:
            è®­ç»ƒæ ·æœ¬åˆ—è¡¨
        """
        samples = []
        
        metadata = structured_data.get('metadata', {})
        analysis = structured_data.get('analysis', {})
        chapters = structured_data.get('chapters', [])
        
        # æå–å…¨å±€ä¿¡æ¯
        characters = analysis.get('characters', {})
        writing_style = analysis.get('writing_style', {})
        tone_mood = analysis.get('tone_mood', {})
        
        # å¤„ç†æ¯ä¸ªç« èŠ‚
        for chapter in chapters:
            chapter_samples = self._generate_chapter_samples(
                chapter, 
                metadata,
                characters,
                writing_style,
                tone_mood,
                use_ai
            )
            samples.extend(chapter_samples)
        
        return samples
    
    def _generate_chapter_samples(self, chapter: Dict, metadata: Dict, 
                                 characters: Dict, writing_style: Dict,
                                 tone_mood: Dict, use_ai: bool) -> List[Dict]:
        """ä»ç« èŠ‚ç”Ÿæˆè®­ç»ƒæ ·æœ¬"""
        samples = []
        
        paragraphs = chapter.get('paragraphs', [])
        dialogues = chapter.get('dialogues', [])
        chapter_characters = chapter.get('characters', {})
        emotional_flow = chapter.get('emotional_flow', [])
        
        # ä¸ºæ¯ä¸ªæ®µè½ç”Ÿæˆæ ·æœ¬
        for para in paragraphs[:20]:  # æ¯ç« æœ€å¤š20æ®µ
            if len(para) < 100:
                continue
            
            # æå–è¯¥æ®µè½çš„ç›¸å…³ä¿¡æ¯
            para_characters = self._extract_paragraph_characters(para, chapter_characters)
            para_emotion = self._extract_paragraph_emotion(para, emotional_flow)
            
            # ç”ŸæˆåŸå§‹æ–‡æœ¬
            original = para[:2000]  # é™åˆ¶é•¿åº¦
            
            # ç”Ÿæˆæ”¹å†™æ–‡æœ¬ï¼ˆåŒ…å«é£æ ¼ã€è¯­æ°”ç­‰ä¿¡æ¯ï¼‰
            rewritten = self._generate_rewritten_with_context(
                original,
                para_characters,
                para_emotion,
                writing_style,
                tone_mood,
                use_ai
            )
            
            if not rewritten or rewritten == original:
                continue
            
            # æ„å»ºè®­ç»ƒæ ·æœ¬ï¼ˆåŒ…å«ä¸°å¯Œä¿¡æ¯ï¼‰
            sample = {
                'original': original,
                'rewritten': rewritten,
                'style': self._get_style_id(metadata.get('category', 'éƒ½å¸‚')),
                'source': metadata.get('title', 'æœªçŸ¥'),
                'site': metadata.get('site', 'm.shuhaige.net'),
                'category': metadata.get('category', 'éƒ½å¸‚'),
                'chapter_num': chapter.get('chapter_num', 0),
                
                # ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
                'characters': para_characters,
                'emotion': para_emotion,
                'writing_style': writing_style.get('style_type', 'å¹³è¡¡å‹'),
                'tone': tone_mood.get('dominant_mood', 'ä¸­æ€§'),
                'dialogue_style': chapter.get('writing_features', {}).get('dialogue_ratio', 0),
                'description_ratio': chapter.get('writing_features', {}).get('description_ratio', 0),
                'action_ratio': chapter.get('writing_features', {}).get('action_ratio', 0),
                
                # äººç‰©æ€§æ ¼å’Œç‰¹å¾
                'character_personalities': self._extract_character_personalities(para_characters, characters),
                'character_speaking_styles': self._extract_character_speaking_styles(para_characters, characters)
            }
            
            samples.append(sample)
        
        return samples
    
    def _extract_paragraph_characters(self, paragraph: str, chapter_characters: Dict) -> List[str]:
        """æå–æ®µè½ä¸­å‡ºç°çš„äººç‰©"""
        characters_in_para = []
        for char_name in chapter_characters.keys():
            if char_name in paragraph:
                characters_in_para.append(char_name)
        return characters_in_para
    
    def _extract_paragraph_emotion(self, paragraph: str, emotional_flow: List[Dict]) -> Optional[str]:
        """æå–æ®µè½æƒ…æ„Ÿ"""
        emotion_keywords = {
            'ç§¯æ': ['å¼€å¿ƒ', 'é«˜å…´', 'å¿«ä¹', 'å…´å¥‹', 'æ»¡è¶³', 'æ»¡æ„', 'å–œæ¬¢', 'çˆ±'],
            'æ¶ˆæ': ['éš¾è¿‡', 'æ‚²ä¼¤', 'ç—›è‹¦', 'æ„¤æ€’', 'å¤±æœ›', 'æ²®ä¸§', 'è®¨åŒ', 'æ¨'],
            'ç´§å¼ ': ['ç´§å¼ ', 'ç„¦è™‘', 'æ‹…å¿ƒ', 'å®³æ€•', 'ææƒ§', 'ä¸å®‰'],
            'å¹³é™': ['å¹³é™', 'å†·é™', 'æ·¡å®š', 'ä»å®¹', 'é•‡å®š']
        }
        
        for emotion, keywords in emotion_keywords.items():
            if any(kw in paragraph for kw in keywords):
                return emotion
        
        return 'ä¸­æ€§'
    
    def _generate_rewritten_with_context(self, original: str, characters: List[str],
                                        emotion: Optional[str], writing_style: Dict,
                                        tone_mood: Dict, use_ai: bool) -> str:
        """ç”ŸæˆåŒ…å«ä¸Šä¸‹æ–‡çš„æ”¹å†™æ–‡æœ¬"""
        # è¿™é‡Œå¯ä»¥è°ƒç”¨AIæˆ–è§„åˆ™æ”¹å†™
        # æš‚æ—¶ä½¿ç”¨ç®€å•çš„è§„åˆ™æ”¹å†™
        rewritten = original
        
        # æ ¹æ®æƒ…æ„Ÿè°ƒæ•´è¯­æ°”
        if emotion == 'ç§¯æ':
            # å¯ä»¥æ·»åŠ ç§¯æçš„è¯­æ°”è¯
            pass
        elif emotion == 'æ¶ˆæ':
            # å¯ä»¥è°ƒæ•´è¯­æ°”
            pass
        
        # æ ¹æ®å†™ä½œé£æ ¼è°ƒæ•´
        style_type = writing_style.get('style_type', 'å¹³è¡¡å‹')
        if style_type == 'è¯¦ç»†æè¿°å‹':
            # å¯ä»¥å¢åŠ æè¿°
            pass
        elif style_type == 'ç®€æ´æ˜å¿«å‹':
            # å¯ä»¥ç®€åŒ–
            pass
        
        return rewritten
    
    def _extract_character_personalities(self, para_characters: List[str], all_characters: Dict) -> Dict:
        """æå–äººç‰©æ€§æ ¼"""
        personalities = {}
        for char_name in para_characters:
            if char_name in all_characters:
                char_info = all_characters[char_name]
                personalities[char_name] = char_info.get('personality', {})
        return personalities
    
    def _extract_character_speaking_styles(self, para_characters: List[str], all_characters: Dict) -> Dict:
        """æå–äººç‰©è¯´è¯é£æ ¼"""
        speaking_styles = {}
        for char_name in para_characters:
            if char_name in all_characters:
                char_info = all_characters[char_name]
                speaking_styles[char_name] = char_info.get('speaking_style', {})
        return speaking_styles
    
    def _get_style_id(self, category: str) -> int:
        """æ ¹æ®åˆ†ç±»è·å–é£æ ¼ID"""
        style_map = {
            'éƒ½å¸‚': 11,
            'ç„å¹»': 8,
            'è¨€æƒ…': 5,
            'æ­¦ä¾ ': 9,
            'ç§‘å¹»': 8,
            'æ‚¬ç–‘': 4,
            'å†å²': 1,
            'å†›äº‹': 7,
            'æ¸¸æˆ': 12,
            'ç«æŠ€': 13,
            'ä»™ä¾ ': 10,
            'å…¶ä»–': 11,
            'æœªçŸ¥': 11,
        }
        return style_map.get(category, 11)
    
    def _validate_samples(self, samples: List[Dict]) -> List[Dict]:
        """éªŒè¯è®­ç»ƒæ ·æœ¬"""
        valid_samples = []
        
        for sample in samples:
            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            if not sample.get('original') or not sample.get('rewritten'):
                continue
            
            orig = sample['original'].strip()
            rew = sample['rewritten'].strip()
            
            # æ£€æŸ¥é•¿åº¦
            if len(orig) < 50 or len(rew) < 50:
                continue
            
            # æ£€æŸ¥é£æ ¼ID
            if not isinstance(sample.get('style'), int):
                continue
            
            valid_samples.append(sample)
        
        return valid_samples
    
    def _save_training_data(self, samples: List[Dict]) -> str:
        """ä¿å­˜è®­ç»ƒæ•°æ®"""
        training_file = os.path.join(self.processed_dir, 'training_data_enhanced.txt')
        
        with open(training_file, 'w', encoding='utf-8') as f:
            for sample in samples:
                orig = sample['original'].replace('\t', ' ').replace('\r', '').replace('\n', ' ').strip()
                rew = sample['rewritten'].replace('\t', ' ').replace('\r', '').replace('\n', ' ').strip()
                
                # é™åˆ¶é•¿åº¦
                if len(orig) > 2000:
                    orig = orig[:2000]
                if len(rew) > 2000:
                    rew = rew[:2000]
                
                # æ„å»ºä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆJSONæ ¼å¼ï¼‰
                context_info = {
                    'characters': sample.get('characters', []),
                    'emotion': sample.get('emotion', 'ä¸­æ€§'),
                    'writing_style': sample.get('writing_style', 'å¹³è¡¡å‹'),
                    'tone': sample.get('tone', 'ä¸­æ€§'),
                    'personalities': sample.get('character_personalities', {}),
                    'speaking_styles': sample.get('character_speaking_styles', {})
                }
                context_str = json.dumps(context_info, ensure_ascii=False)
                
                # TSVæ ¼å¼ï¼šåŸå§‹æ–‡æœ¬<TAB>æ”¹å†™æ–‡æœ¬<TAB>é£æ ¼ID<TAB>ä¸Šä¸‹æ–‡JSON
                f.write(f"{orig}\t{rew}\t{sample['style']}\t{context_str}\n")
        
        print(f"\nâœ… è®­ç»ƒæ•°æ®å·²ä¿å­˜: {training_file}")
        print(f"   æ ·æœ¬æ•°: {len(samples)}")
        
        return training_file

