#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´å·¥ä½œæµç¨‹æ‰§è¡Œè„šæœ¬
ä¿®å¤æ‰€æœ‰å¯¼å…¥é—®é¢˜ï¼Œç¡®ä¿æµç¨‹å®Œæ•´æ‰§è¡Œ
"""

import os
import sys

# æ·»åŠ è·¯å¾„
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(script_dir))
sys.path.insert(0, script_dir)
sys.path.insert(0, project_root)
sys.path.insert(0, os.path.join(project_root, 'scripts'))

# å¯¼å…¥æ¨¡å—
from core.pipeline import DataPipeline

def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*60)
    print("ğŸš€ å®Œæ•´å·¥ä½œæµç¨‹è‡ªåŠ¨æ‰§è¡Œ")
    print("="*60)
    
    # åˆå§‹åŒ–æµæ°´çº¿
    pipeline = DataPipeline("data/training")
    
    # æ£€æŸ¥ç°æœ‰æ•°æ®
    novels_dir = pipeline.novels_dir
    novel_files = []
    if os.path.exists(novels_dir):
        for root, dirs, files in os.walk(novels_dir):
            for file in files:
                if file.endswith('.txt'):
                    novel_files.append(os.path.join(root, file))
    
    if not novel_files:
        print("\nâŒ æœªæ‰¾åˆ°å°è¯´æ•°æ®")
        return False
    
    print(f"\nâœ… æ‰¾åˆ° {len(novel_files)} æœ¬å°è¯´")
    
    # æ‰§è¡Œå®Œæ•´æµç¨‹ï¼ˆè·³è¿‡çˆ¬å–ï¼Œä½¿ç”¨å·²æœ‰æ•°æ®ï¼‰
    success = pipeline.run_full_pipeline(
        site_name=None,  # ä¸çˆ¬å–
        category=None,   # ä¸çˆ¬å–
        count=0,
        use_ai=False,
        epochs=10,
        batch_size=8,
        incremental=False,
        organize_data=False,
        skip_steps=['scrape']  # è·³è¿‡çˆ¬å–
    )
    
    if success:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        print("\n" + "="*60)
        print("ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶")
        print("="*60)
        
        import shutil
        cleaned = 0
        
        # æ¸…ç†.tempç›®å½•
        for root, dirs, files in os.walk(pipeline.output_dir):
            if '.temp' in root:
                try:
                    shutil.rmtree(root)
                    cleaned += 1
                    print(f"   ğŸ—‘ï¸  å·²æ¸…ç†: {os.path.basename(root)}")
                except:
                    pass
        
        # æ¸…ç†è¿›åº¦æ–‡ä»¶
        for root, dirs, files in os.walk(pipeline.output_dir):
            for file in files:
                if file.endswith('_progress.json') or file.endswith('.tmp'):
                    try:
                        os.remove(os.path.join(root, file))
                        cleaned += 1
                    except:
                        pass
        
        if cleaned > 0:
            print(f"\nâœ… æ¸…ç†å®Œæˆ: {cleaned} ä¸ªæ–‡ä»¶/ç›®å½•")
        else:
            print("â„¹ï¸  æ²¡æœ‰éœ€è¦æ¸…ç†çš„ä¸´æ—¶æ–‡ä»¶")
        
        # æœ€ç»ˆéªŒè¯
        print("\n" + "="*60)
        print("ğŸ“‹ æœ€ç»ˆéªŒè¯")
        print("="*60)
        
        # æ£€æŸ¥æ¨¡å‹
        model_files = [
            os.path.join(pipeline.model_path, 'best_model.h5'),
            os.path.join(pipeline.model_path, 'final_model.h5'),
            os.path.join(pipeline.model_path, 'vocab.json')
        ]
        
        existing = [f for f in model_files if os.path.exists(f)]
        if existing:
            print(f"âœ… æ¨¡å‹æ–‡ä»¶: {len(existing)}/{len(model_files)} ä¸ªæ–‡ä»¶å·²ç”Ÿæˆ")
            for f in existing:
                size = os.path.getsize(f) / 1024 / 1024
                print(f"   - {os.path.basename(f)}: {size:.2f} MB")
        else:
            print("âŒ æ¨¡å‹æ–‡ä»¶æœªç”Ÿæˆ")
            return False
        
        print("\n" + "="*60)
        print("ğŸ‰ å®Œæ•´å·¥ä½œæµç¨‹æ‰§è¡ŒæˆåŠŸï¼")
        print("="*60)
        return True
    else:
        print("\nâŒ å·¥ä½œæµç¨‹æ‰§è¡Œå¤±è´¥")
        return False


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)

